{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjsYNlKYmzwtZLbBBputB4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-An5ir8NeSpr"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn   \n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from rembg.bg import remove\n",
        "from focal_loss.focal_loss import FocalLoss\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egNJVh65e8IP"
      },
      "source": [
        "##Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU-ol-z7e4LU"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "#    transforms.RandomHorizontalFlip(),\n",
        "#    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=(0, 180)),\n",
        "#    transforms.RandomPerspective(),\n",
        "#    transforms.RandomInvert(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "#    transforms.RandomInvert(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD8hMuCAfRVS"
      },
      "source": [
        "train_another_dataset = torchvision.datasets.ImageFolder(data_train, train_transforms)\n",
        "\n",
        "batch_size = 8\n",
        "train_another_dataloader = torch.utils.data.DataLoader(\n",
        "    train_another_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eir61RnsfYaE"
      },
      "source": [
        "len(train_dataloader), len(train_end_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDdDJY9yfcg8"
      },
      "source": [
        "X_batch, y_batch = next(iter(train_dataloader))\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "plt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVPqilTAffS8"
      },
      "source": [
        "def show_input(input_tensor, title=''):\n",
        "    image = input_tensor.permute(1, 2, 0).numpy()\n",
        "    image = std * image + mean\n",
        "    plt.imshow(image.clip(0, 1))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "    plt.pause(0.001)\n",
        "\n",
        "X_batch, y_batch = next(iter(train_dataloader))\n",
        "\n",
        "for x_item, y_item in zip(X_batch, y_batch):\n",
        "    show_input(x_item, title=class_names[y_item])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0QMkdtMgg89"
      },
      "source": [
        "##Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KAxbo5PfgJ9"
      },
      "source": [
        "def train_model(model, loss, optimizer, scheduler, num_epochs, data_tr, data_val, device):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                dataloader = train_dataloader\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                dataloader = val_dataloader\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward and backward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    preds = model(inputs)\n",
        "                    loss_value = loss(preds, labels)\n",
        "                    preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss_value.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss_value.item()\n",
        "                running_acc += (preds_class == labels.data).float().mean()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader)\n",
        "            epoch_acc = running_acc / len(dataloader)\n",
        "\n",
        "            epl = 0\n",
        "            epcc = 0\n",
        "            if phase == 'val':\n",
        "                epl = epoch_loss\n",
        "                epcc = epoch_acc.item()\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
        "\n",
        "    return [model, epl, epcc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXDDLF88gnO2"
      },
      "source": [
        "##Mod-resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gripZj36glrZ"
      },
      "source": [
        "def modified_resnet():\n",
        "    model = models.resnet152(pretrained=True)\n",
        "    #model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))\n",
        "\n",
        "    # Disable grad for all conv layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.avgpool = torch.nn.Sequential(\n",
        "#        torch.nn.Dropout(),\n",
        "#        summ_layer(),\n",
        "        torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "    )\n",
        "\n",
        "\n",
        "    model.fc =  torch.nn.Sequential(\n",
        "        torch.nn.Dropout(),\n",
        "        torch.nn.Linear(model.fc.in_features, 2))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdz96RQog7Ep"
      },
      "source": [
        "##K-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKqUHTUag38F"
      },
      "source": [
        "kfold = KFold(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_gH5EDwhCOS"
      },
      "source": [
        "def k_fold():\n",
        "  full_loss = []\n",
        "  full_acc = []\n",
        "  for train_index, test_index in kfold.split(train_end_dataset):  \n",
        "    model = modified_resnet()\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    #loss = torch.nn.CrossEntropyLoss()\n",
        "    loss = FocalLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "    \n",
        "    \n",
        "    train_tensor = [train_end_dataset[i] for i in train_index]\n",
        "    val_tensor = [train_end_dataset[i] for i in test_index]\n",
        "\n",
        "    batch_size = 10\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_tensor, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_tensor, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    _, ep_loss, ep_acc = train_model(model, loss, optimizer, scheduler, num_epochs=20, data_tr = train_dataloader, data_val = val_dataloader, device = device)\n",
        "\n",
        "    full_loss.append(ep_loss)\n",
        "    full_acc.append(ep_acc)\n",
        "\n",
        "  return [np.mean(full_loss), np.mean(full_acc)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Ms93tjhLjX"
      },
      "source": [
        "##Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TU6BODThK00"
      },
      "source": [
        "result_metrics = k_fold()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}